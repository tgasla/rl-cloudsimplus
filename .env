# RL stuff
ALGO=PPO

# ------------------PRETRAIN PARAMETERS-----------------------#
PRETRAIN_TIMESTEPS=50000000
PRETRAIN_HOSTS=10
PRETRAIN_HOST_PES=10
PRETRAIN_HOST_PE_MIPS=10

# max pes per job cannot be greater than the largest VM's cores
PRETRAIN_MAX_JOB_PES=1
PRETRAIN_JOB_TRACE_FILENAME=100jobs_5lambda_1000mi

# Reward parameter coefficients
PRETRAIN_REWARD_JOB_WAIT_COEF=0.5
PRETRAIN_REWARD_UTIL_COEF=0.5
PRETRAIN_REWARD_INVALID_COEF=0.0
# ------------------------------------------------------------#


# If PRETRAIN_DIR is empty, then pretarining is done using
# the pretrain parameters
# If PRETRAIN_DIR is not empty, then pretraining is not done
# and the model is loaded from the directory
#PRETRAIN_DIR=
PRETRAIN_DIR=240412-020710_PPO_20M_10H_10P_10M_100jobs_1lambda_1000mi_1MJC_0.3Q_0.3U_0.4I_1
# leave transfer timesteps blank if not transfer is needed
TRANSFER_TIMESTEPS=1000000
#TRANSFER_TIMESTEPS=
TRANSFER_HOSTS=10
TRANSFER_HOST_PES=10
TRANSFER_HOST_PE_MIPS=10

TRANSFER_MAX_JOB_PES=1
TRANSFER_JOB_TRACE_FILENAME=100jobs_5lambda_1000mi

TRANSFER_REWARD_JOB_WAIT_COEF=0.5
TRANSFER_REWARD_UTIL_COEF=0.5
TRANSFER_REWARD_INVALID_COEF=0

# speedup controls the speed in which the jobs are coming
# and when will the last job come.
# in LLNL-Atlas job trace, 1000 means: last job arrives 180 seconds after the first one
# in simulation you have x200 speedup related to wall-clock time
SIMULATION_SPEEDUP=1


# If both pretrain and transfer timesteps are specified, the agent trains on the pratraining
# environment and then gets transfered to the transfer environment

# If you want to disable retraining on the transfer environment then you should:
# (1) do not change the learning rate or any parameters of the model 
# (2) set reset_num_timesteps=False when calling model.learn(..)

# On the other hand, if you want to enable retraining:
# (1) set the learning rate of the model to a small number, ideally smaller than the initial default
# (2) set reset_num_timesteps=True when calling model.learn(..)
