{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "from rich.progress import Progress\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Autoencoder Model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, dropout=0.0, use_batch_norm=False):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128) if use_batch_norm else nn.Identity(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(latent_dim) if use_batch_norm else nn.Identity(),\n",
    "            nn.Sigmoid(),  # Output values are normalized to [0, 1]\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128) if use_batch_norm else nn.Identity(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid(),  # Assuming input values are normalized to [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return latent, reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class to handle CSV input and padding\n",
    "class TreeDataset(Dataset):\n",
    "    def __init__(self, csv_file, padding_length=161):\n",
    "        # Load data from CSV\n",
    "        self.padding_length = padding_length\n",
    "        self.data = self._load_csv(csv_file)\n",
    "\n",
    "    def _min_max_normalize(self, array, min_val=0, max_val=100):\n",
    "        \"\"\"\n",
    "        Normalize array to the range [0, 1] based on given min_val and max_val.\n",
    "        \"\"\"\n",
    "        array = np.array(array, dtype=np.float32)\n",
    "        return (array - min_val) / (max_val - min_val)\n",
    "\n",
    "    def _load_csv(self, csv_file):\n",
    "        \"\"\"Read CSV file using Python's built-in csv module.\"\"\"\n",
    "        data = []\n",
    "        with open(csv_file, \"r\") as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            with Progress() as progress:\n",
    "                task = progress.add_task(\n",
    "                    \"[cyan]Processing CSV...\", total=sum(1 for _ in csvfile)\n",
    "                )  # Total rows in file\n",
    "                csvfile.seek(0)  # Reset file pointer\n",
    "\n",
    "                for row in reader:\n",
    "                    row = list(map(int, row))\n",
    "                    normalized_row = self._min_max_normalize(row)\n",
    "                    data.append(normalized_row)\n",
    "                    # Update progress bar\n",
    "                    progress.update(task, advance=1)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the length of the dataset (number of rows).\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Retrieve a single data point from the dataset.\"\"\"\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_for_everything(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, epochs, train_loader):\n",
    "    print(f\"Training the Autoencoder, Total epochs: {epochs}\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_rmse = 0\n",
    "        total_samples = 0\n",
    "        for batch in tqdm(\n",
    "            train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\", unit=\"batch\"\n",
    "        ):\n",
    "            optimizer.zero_grad()\n",
    "            _, reconstructed = model(batch)\n",
    "            loss = criterion(reconstructed, batch)  # Reconstruction loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            batch_size = batch.size(0)\n",
    "            total_samples += batch_size\n",
    "            epoch_loss += loss.item() * batch_size  # Weighted by batch size\n",
    "\n",
    "            # Calculate and accumulate RMSE\n",
    "            rmse = torch.sqrt(loss)  # RMSE = sqrt(MSE)\n",
    "            epoch_rmse += rmse.item() * batch_size  # Weighted by batch size\n",
    "\n",
    "        # Compute average loss and RMSE over all samples\n",
    "        epoch_loss /= total_samples\n",
    "        epoch_rmse /= total_samples\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.6f}, RMSE: {epoch_rmse:.6f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, criterion, val_loader):\n",
    "    ###\n",
    "    # Validate the model\n",
    "    ###\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_rmse = 0\n",
    "    total_samples = 0\n",
    "    latent_representations = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validating...\", unit=\"batch\"):\n",
    "            latent, reconstructed = model(batch)\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            batch_size = batch.size(0)\n",
    "            total_samples += batch_size\n",
    "            val_loss += loss.item() * batch_size\n",
    "\n",
    "            latent_representations.append(latent)\n",
    "\n",
    "            rmse = torch.sqrt(loss)\n",
    "            val_rmse += rmse.item() * batch_size\n",
    "\n",
    "    val_loss /= total_samples\n",
    "    val_rmse /= total_samples\n",
    "\n",
    "    latent_representations = torch.cat(latent_representations).numpy()\n",
    "    print(f\"Latent representations shape: {latent_representations.shape}\")\n",
    "    print(f\"Validation Loss: {val_loss:.6f}, Validation RMSE: {val_rmse:.6f}\")\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd659b80cfde4eb49cb34fcdd996db84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 2551965\n",
      "Train size: 2041572\n",
      "Validation size: 510393\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "seed = 1234\n",
    "set_seed_for_everything(seed=seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "# Load dataset\n",
    "csv_file = \"data/5hosts_and_10hosts_train_data.csv\"  # Replace with your CSV file path\n",
    "dataset = TreeDataset(csv_file)\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "train_size = int(0.8 * len(dataset))\n",
    "print(f\"Train size: {train_size}\")\n",
    "val_size = len(dataset) - train_size\n",
    "print(f\"Validation size: {val_size}\")\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True, worker_init_fn=seed, generator=g\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False, worker_init_fn=seed, generator=g\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Autoencoder, Total epochs: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]: 100%|██████████| 63800/63800 [01:54<00:00, 556.51batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.000291, RMSE: 0.004376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]: 100%|██████████| 63800/63800 [01:24<00:00, 752.02batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.000005, RMSE: 0.002238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]: 100%|██████████| 63800/63800 [02:13<00:00, 476.29batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.000004, RMSE: 0.001975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]: 100%|██████████| 63800/63800 [01:24<00:00, 756.86batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.000004, RMSE: 0.001809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]: 100%|██████████| 63800/63800 [02:19<00:00, 457.26batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.000003, RMSE: 0.001716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]: 100%|██████████| 63800/63800 [00:58<00:00, 1098.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.000003, RMSE: 0.001654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]: 100%|██████████| 63800/63800 [01:06<00:00, 959.94batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.000003, RMSE: 0.001603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]: 100%|██████████| 63800/63800 [02:32<00:00, 419.40batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.000003, RMSE: 0.001562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]: 100%|██████████| 63800/63800 [02:01<00:00, 524.89batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.000003, RMSE: 0.001531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]: 100%|██████████| 63800/63800 [02:27<00:00, 431.62batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.000002, RMSE: 0.001512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating...: 100%|██████████| 15950/15950 [00:02<00:00, 5908.24batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent representations shape: (510393, 64)\n",
      "Validation Loss: 0.000009, Validation RMSE: 0.002931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = 161  # Number of features\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Track best configuration\n",
    "best_val_rmse = float(\"inf\")\n",
    "best_params = {}\n",
    "best_model = None\n",
    "\n",
    "# Define hyperparameters\n",
    "lr = 0.001\n",
    "weight_decay = 0\n",
    "dropout = 0\n",
    "latent_dim = 64\n",
    "use_batch_norm = True\n",
    "epochs = 10\n",
    "\n",
    "model = Autoencoder(\n",
    "    input_dim=input_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    dropout=dropout,\n",
    "    use_batch_norm=use_batch_norm,\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, criterion, optimizer, epochs, train_loader)\n",
    "\n",
    "# Validate the model\n",
    "rmse = validate_model(model, criterion, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "torch.save(model.state_dict(), \"AE_5hosts_and_10hosts_64_BN.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###\n",
    "# # Testing the best model\n",
    "# ###\n",
    "\n",
    "# # Load the best model for testing\n",
    "# best_model = Autoencoder(\n",
    "#     input_dim=input_dim,\n",
    "#     latent_dim=best_params[\"latent_dim\"],\n",
    "#     dropout=best_params[\"dropout\"],\n",
    "#     use_batch_norm=best_params[\"use_batch_norm\"],\n",
    "# )\n",
    "\n",
    "# best_model.load_state_dict(torch.load(\"best_autoencoder.pth\"))\n",
    "# best_model.eval()\n",
    "\n",
    "# test_loss = 0\n",
    "# test_rmse = 0\n",
    "# total_samples = 0\n",
    "\n",
    "# test_loader = DataLoader(\n",
    "#     test_dataset, batch_size=best_params[\"batch_size\"], shuffle=False\n",
    "# )\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_loader, desc=\"Testing...\", unit=\"batch\"):\n",
    "#         _, reconstructed = best_model(batch)\n",
    "#         loss = criterion(reconstructed, batch)\n",
    "#         batch_size = batch.size(0)\n",
    "#         total_samples += batch_size\n",
    "\n",
    "#         test_loss += loss.item() * batch_size\n",
    "\n",
    "#         rmse = torch.sqrt(loss)\n",
    "#         test_rmse += rmse.item() * batch_size\n",
    "\n",
    "# test_loss /= total_samples\n",
    "# test_rmse /= total_samples\n",
    "\n",
    "# print(f\"Test Loss: {test_loss:.6f}, Test RMSE: {test_rmse:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model.load_state_dict(torch.load(\"model_path.pth\"))\n",
    "\n",
    "# Step 4: Set the model to evaluation mode\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
