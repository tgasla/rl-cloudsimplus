# train_model_dir: applicable only if mode == [transfer|test]
# globals.java_log_destination: [none, stdout, file, stdout-file] - if file, logs are written to a file, if stdout-file, logs are written to both stdout and a file
# globals.junit_output_show: [true, false] - if true, junit test results are printed to stdout
# globals.java_log_level: [TRACE, DEBUG, INFO, WARNING, ERROR]
# seed: random or any integer
# base_log_dir: parent directory for all logs
# experiment_type_dir: parent directory for a set of experiments
# experiment_name: name of the experiment
# mode: [train, test, transfer]
# vm_allocation_policy: [rl, heuristic]
# algorithm: [any stable-baselines3 algorithm if vm_allocation_policy == rl, bestfit|firstfit|worstfit|roundrobin|random if vm_allocation_policy == heuristic]

# globals.run_mode: [batch, serial]

# if you make any changes in java_log_leve, java_log_destination or java_output_show, 
#  you need to execute make build-gateway for the changes to take effect
globals:
    attached: true
    gpu: true
    java_log_level: INFO
    java_log_destination: none
    junit_output_show: false
    run_mode: serial

common:
    timestep_interval: 1.0
    initial_s_vm_count: 0
    initial_m_vm_count: 0
    initial_l_vm_count: 0
    max_episode_length: 100
    vm_startup_delay: 0.0
    vm_shutdown_delay: 0.0
    split_large_jobs: true
    clear_created_lists: true
    host_ram: 65536
    host_storage: 100000
    host_bw: 50000
    small_vm_ram: 8192
    small_vm_storage: 4000
    small_vm_bw: 1000
    paying_for_the_full_hour: false
    small_vm_hourly_cost: 0.086
    save_experiment: true
    base_log_dir: logs
    experiment_type_dir: train_50_hosts_8maxcores
    mode: train
    vm_allocation_policy: rl
    enable_autoencoder_observation: false
    algorithm: PPO
    max_hosts: 100
    host_count: 50
    host_pes: 64
    host_pe_mips: 50000
    max_job_pes: 4
    medium_vm_multiplier: 2
    large_vm_multiplier: 4
    small_vm_pes: 2
    job_trace_filename: gaussian_max1600_8maxcores.csv
    timesteps: 2000000
    reward_job_wait_coef: 0.25
    reward_running_vm_cores_coef: 0.25
    reward_unutilized_vm_cores_coef: 0.25
    reward_invalid_coef: 0.25

experiment_1:
    seed: 42
    experiment_name: tree_42
    # train_model_dir: 30maxentropy_4maxcores_10mi_10hosts_noise_2M/autoencoder_10hosts_64_BN_2345

experiment_2:
    seed: 1234
    experiment_name: tree_1234
#     # train_model_dir: 30maxentropy_4maxcores_10mi_10hosts_noise_2M/autoencoder_10hosts_64_BN_3456

experiment_3:
    seed: 2345
    experiment_name: tree_2345
#     # train_model_dir: 30maxentropy_4maxcores_10mi_10hosts_noise_2M/autoencoder_10hosts_64_BN_4567

experiment_4:
    seed: 3456
    experiment_name: tree_3456
#     # train_model_dir: 30maxentropy_4maxcores_10mi_10hosts_noise_2M/autoencoder_10hosts_64_BN_5678

experiment_5:
    seed: 4567
    experiment_name: tree_4567

experiment_6:
    seed: 5678
    experiment_name: tree_5678

experiment_7:
    seed: 6789
    experiment_name: tree_6789

experiment_8:
    seed: 7890
    experiment_name: tree_7890

experiment_9:
    seed: 8901
    experiment_name: tree_8901

experiment_10:
    seed: 9012
    experiment_name: tree_9012

experiment_11:
    seed: 3210
    experiment_name: tree_3210
    
# experiment_5:
#     state_representation: treearray
#     mode: train
#     vm_allocation_policy: heuristic
#     algorithm: bestfit
#     host_count: 10
#     host_pes: 10
#     host_pe_mips: 10
#     max_job_pes: 1
#     small_vm_pes: 2
#     job_trace_filename: two_peaks_max30
#     timesteps: 1000000
#     reward_job_wait_coef: 0.33
#     reward_running_vm_cores_coef: 0.33
#     reward_unutilized_vm_cores_coef: 0.33
#     reward_invalid_coef: 0.0




# experiment_6:
#     state_representation: treearray
#     mode: train
#     vm_allocation_policy: heuristic
#     algorithm: bestfit
#     host_count: 10
#     host_pes: 10
#     host_pe_mips: 10
#     max_job_pes: 1
#     small_vm_pes: 2
#     job_trace_filename: descending_max30
#     timesteps: 1000000
#     reward_job_wait_coef: 0.33
#     reward_running_vm_cores_coef: 0.33
#     reward_unutilized_vm_cores_coef: 0.33
#     reward_invalid_coef: 0.0

# experiment_7:
#     state_representation: treearray
#     mode: train
#     vm_allocation_policy: heuristic
#     algorithm: bestfit
#     host_count: 10
#     host_pes: 10
#     host_pe_mips: 10
#     max_job_pes: 1
#     small_vm_pes: 2
#     job_trace_filename: ascending_max30
#     timesteps: 1000000
#     reward_job_wait_coef: 0.33
#     reward_running_vm_cores_coef: 0.33
#     reward_unutilized_vm_cores_coef: 0.33
#     reward_invalid_coef: 0.0

# experiment_8:
#     state_representation: treearray
#     mode: train
#     vm_allocation_policy: heuristic
#     algorithm: bestfit
#     host_count: 10
#     host_pes: 10
#     host_pe_mips: 10
#     max_job_pes: 1
#     small_vm_pes: 2
#     job_trace_filename: hill_max30
#     timesteps: 1000000
#     reward_job_wait_coef: 0.33
#     reward_running_vm_cores_coef: 0.33
#     reward_unutilized_vm_cores_coef: 0.33
#     reward_invalid_coef: 0.0

# experiment_9:
#     state_representation: treearray
#     mode: train
#     vm_allocation_policy: heuristic
#     algorithm: bestfit
#     host_count: 10
#     host_pes: 10
#     host_pe_mips: 10
#     max_job_pes: 1
#     small_vm_pes: 2
#     job_trace_filename: valley_max30
#     timesteps: 1000000
#     reward_job_wait_coef: 0.33
#     reward_running_vm_cores_coef: 0.33
#     reward_unutilized_vm_cores_coef: 0.33
#     reward_invalid_coef: 0.0
