services:
  # uses port 25333 by default
  gateway:
    image: gateway:2.0.0
    container_name: gateway
    environment:
      - INITIAL_S_VM_COUNT=0
      - INITIAL_M_VM_COUNT=0
      - INITIAL_L_VM_COUNT=0
      - MAX_EPISODE_LENGTH=100
      - TIMESTEP_INTERVAL=1
      - SPLIT_LARGE_JOBS=true
      - MAX_JOB_PES=1
      - VM_HOURLY_COST=0.086
      - HOSTS_COUNT=10
      - HOST_PE_MIPS=10
      - HOST_PES=10
      - HOST_RAM=65536
      - HOST_STORAGE=100000
      - HOST_BW=50000
      - SMALL_VM_PES=2
      - SMALL_VM_RAM=8192
      - SMALL_VM_STORAGE=4000
      - SMALL_VM_BW=1000
      - VM_STARTUP_DELAY=0
      - VM_SHUTDOWN_DELAY=0
      - PAYING_FOR_THE_FULL_HOUR=false
      - KEEP_CREATED_CLOUDLET_LIST=false
      - REWARD_JOB_WAIT_COEF=0.3
      - REWARD_UTIL_COEF=0.3
      - REWARD_INVALID_COEF=0.4
    volumes:
      - ./logs:/app/logs

  manager: &cpu
    profiles: [ "" ]
    image: manager:0.10
    container_name: manager
    build: rl-manager
    depends_on:
      - gateway
    environment:
      - ALGO=PPO
      - TRAINING_TIMESTEPS=1000000
      - MAX_JOB_PES=1
      - HOSTS_COUNT=10
      - HOST_PE_MIPS=10
      - HOST_PES=10
      - SMALL_VM_PES=2
      - REWARD_JOB_WAIT_COEF=0.3
      - REWARD_UTIL_COEF=0.3
      - REWARD_INVALID_COEF=0.4
      - JOB_TRACE_FILENAME=gradual
    volumes:
      - ./logs:/mgr/logs
      - ./rl-manager/mnt:/mgr/mnt
    command: >
      python3 mnt/train.py
    # command: python3 mnt/test.py

  manager-cuda:
    <<: *cpu
    profiles: [ "cuda" ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
